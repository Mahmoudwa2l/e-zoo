{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: limegreen; font-family: 'Maven Pro', sans-serif;\"> LAB 1 MEDIAPIPE <img src=\"google.png\" alt=\"Google Icon\" width=\"35\" height=\"35\"> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show image function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimage(image):\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show hand image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('A:\\e-zoo\\Labs\\hand.jpeg')\n",
    "showimage(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands=mp.solutions.hands\n",
    "mp_drawings=mp.solutions.drawing_utils\n",
    "mp_styles=mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the BGR image to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[classification {\n",
      "  index: 1\n",
      "  score: 0.92240083\n",
      "  label: \"Right\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "hands = mp_hands.Hands(static_image_mode=True,max_num_hands=2, min_detection_confidence=0.7)\n",
    "rgb_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "results = hands.process(rgb_image)\n",
    "print(results.multi_handedness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw hands connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 :\n",
      "359.3548893928528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_height,image_width,_=image.shape\n",
    "annotated_image = image.copy()\n",
    "for hand_landmarks in results.multi_hand_landmarks :\n",
    "    print(\"index 0 :\")\n",
    "    print(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x*image_width)\n",
    "    mp_drawings.draw_landmarks(annotated_image,hand_landmarks,mp_hands.HAND_CONNECTIONS,mp_styles.get_default_hand_landmarks_style(),mp_styles.get_default_hand_connections_style())\n",
    "\n",
    "showimage(annotated_image)\n",
    "cv2.imwrite(\"A:/e-zoo/Labs/hand_points.jpg\",annotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: gold; font-family: 'Maven Pro', sans-serif;\">LAB 2 Socket  <img src=\"power-plug.png\" width=\"50\" height=\"50\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"A:\\e-zoo\\Labs\\hand.jpeg\"\n",
    "image = cv2.imread(path)\n",
    "showimage(image)\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.95084953308105,560.2206852436066,329.636013507843,510.9414232969284,404.8642158508301,437.0177946090698,472.3484516143799,379.47614216804504,530.2489042282104,349.2258051633835,313.70619535446167,311.37352418899536,334.76446866989136,206.38581943511963,345.2597379684448,142.7808699309826,352.63277292251587,88.0012372136116,251.41743421554565,305.5555012822151,257.47377276420593,191.56237828731537,259.9393129348755,118.43933826684952,260.9978377819061,59.222829699516296,193.05764436721802,322.3116235136986,186.43909692764282,214.95215272903442,185.5600655078888,149.11481714248657,186.78077459335327,94.72056007385254,136.8799924850464,358.277016043663,105.56126832962036,282.15023905038834,86.0860526561737,230.9569342136383,73.14105033874512,181.36137175559998,\n"
     ]
    }
   ],
   "source": [
    "data=\"\"\n",
    "with mp_hands.Hands(static_image_mode = True , max_num_hands=2,min_detection_confidence=0.7) as hands :\n",
    "    rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    flippedImage = cv2.flip(rgb,1)\n",
    "    results = hands.process(flippedImage)\n",
    "    image_height,image_width,_ = image.shape\n",
    "\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        for point in range(21):\n",
    "            data+=str(hand_landmarks.landmark[point].x*image_width)+ \",\"+str(hand_landmarks.landmark[point].y*image_height)+\",\"\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a connection...\n",
      "Device connected: ('127.0.0.1', 56477)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mySocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # Create a TCP socket\n",
    "mySocket.bind(('localhost', 5000))  # Bind to the address using a tuple\n",
    "mySocket.listen(5)\n",
    "print(\"Waiting for a connection...\")\n",
    "\n",
    "conn, addr = mySocket.accept()\n",
    "print(f\"Device connected: {addr}\")\n",
    "\n",
    "msg = bytes(data, 'utf-8')\n",
    "conn.send(msg)\n",
    "\n",
    "conn.close()  # Close the connection after sending the message\n",
    "mySocket.close()  # Close the listening socket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "772"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "mySocket = socket.socket()\n",
    "mySocket.bind(('localhost',5000))\n",
    "mySocket.listen(5)\n",
    "conn ,addr = mySocket.accept()\n",
    "print(\"device connected\")\n",
    "msg = bytes(data,'utf-8')\n",
    "conn.send(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: skyblue; font-family: 'Maven Pro', sans-serif;\">LAB 3 MEDIAPIPE & DOLLARPY  <img src=\"dollar-symbol.png\" width=\"45\" height=\"45\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MediaPipe and Dollarpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from dollarpy import Recognizer, Template,Point\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mp_drawings = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to extract pose landmarks and convert them to POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#D678ED ; font-family: 'Maven Pro', sans-serif;\">LAB 4 TUIO   <img src=\"touch.png\" width=\"60\" height=\"60\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5 Face materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 6 YOLOv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 7 Gaze Tracking & Facial Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
